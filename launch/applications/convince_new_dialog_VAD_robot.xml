<application>
    <name>convince_new_dialog_VAD_robot</name>

    <module>
        <name>yarprobotinterface</name>
        <parameters>--context speechPipeline --from micAudio.ini --mic_sound_on_stop 0 --mic_start 1 --mic_min_samples 4000 --mic_max_samples 4000</parameters>
        <node>r1-torso</node>
    </module>

    <module>
        <name>python3</name>
        <parameters>oww.py</parameters>
        <workdir>$ENV{TOUR_GUIDE_ROBOT_SOURCE_DIR}/aux_modules/speechProcessing/openWakeWord</workdir>
        <node>console-llm</node>
    </module>

    <module>
        <name>sileroVAD</name>
        <parameters></parameters>
        <environment>YARP_LOG_PROCESS_LABEL=VAD</environment>
        <node>console-llm</node>
    </module>

    <module>
        <name>python3</name>
        <parameters>play_notification.py</parameters>
        <node>r1-face</node>
        <workdir>$ENV{TOUR_GUIDE_ROBOT_SOURCE_DIR}/aux_modules/speechProcessing/wakeWordDetection</workdir>
    </module>

    <module>
        <name>yarprobotinterface</name>
        <parameters>--context vadModule --from audioPlayer.ini</parameters>
        <node>r1-face</node>
    </module>

    <module>
        <name>yarprobotinterface</name>
        <parameters>--context convince --from madamaChat.ini</parameters>
        <environment></environment>
        <node>console-llm</node>
    </module>

    <module>
        <name>yarprobotinterface</name>
        <parameters>--context convince --from poiMadamaChat.ini </parameters>
        <environment></environment>
        <node>console-llm</node>
    </module>

    <module>
        <name>yarprobotinterface</name>
        <parameters>--context convince --from welcomeTalkChat.ini </parameters>
        <environment></environment>
        <node>console-llm</node>
    </module>

    <module>
        <name>yarprobotinterface</name>
        <parameters>--context speechPipeline --from azureSynthesizer.ini</parameters>
        <environment></environment>
        <node>console-llm</node>
    </module>

    <module>
        <name>yarprobotinterface</name>
        <parameters>--context speechPipeline --from azureTranscription.ini</parameters>
        <environment></environment>
        <node>console-llm</node>
    </module>


    <connection>
        <from>/audioRecorder_nws/audio:o</from>
        <to>/wake/audio:i</to>
    </connection>

    <connection>
        <from>/wake/audio:o</from>
        <to>/vad/audio:i</to>
    </connection>

    <connection>
        <from>/vad/rpc:o</from>
        <to>/wake/rpc:i</to>
        <protocol>fast_tcp</protocol>
    </connection>

    <connection>
        <from>/wake/notification:o</from>
        <to>/wake_notification:i</to>
        <protocol>fast_tcp</protocol>
    </connection>
    
    <connection>
        <from>/wake/face:o</from>
        <to>/faceExpressionImage/rpc </to>
        <protocol>fast_tcp</protocol>
    </connection>

    <connection>
        <from>/vad/audio:o</from>
        <to>/SpeechToTextComponent/audio:i</to>
    </connection>
    <!-- 
    <connection>
        <from>/speechTranscription_nws/text:o</from>
        <to>/cutString/text:i</to>
    </connection> -->

</application>
